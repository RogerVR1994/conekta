{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conekta Code Challenge\n",
    "\n",
    "The objective of the challenge is to create a data pipeline for a CSV file that contains transactions from different companies. There are 4 steps in the process:\n",
    "* Load\n",
    "* Transform\n",
    "* Separate Tables\n",
    "* Create Final View\n",
    "\n",
    "This code uses Python because of the ease of use and fast implementation. For a small task like this Python with Pandas is a good choice since we're not dealing with a great amount of data. For bigger data files or more complex transformations we should use other libraries or other languages.\n",
    "\n",
    "MySQL is the preferred database to use since it's easy to manage and the data is alredy structured and small. These are the reasons why a No-SQL database would not be appropriate for this solution\n",
    "\n",
    "## Step 1\n",
    "Install all needed dependencies for Python, including sql libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install mysql-connector-python\n",
    "!pip install sqlalchemy\n",
    "!sudo apt-get install libmysqlclient-dev -y\n",
    "!pip install mysqlclient\n",
    "!pip install psycopg2-binary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps 2 and 3\n",
    "Transform the data to the desired structure and load it to a DB. \n",
    "The MySQL database is located on an AWS RDS server using the free tier for development purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, types\n",
    "\n",
    "db = create_engine(\"mysql://admin:conekta2020@database-1.c122pa8govmo.us-east-1.rds.amazonaws.com:3306/conekta\")\n",
    "\n",
    "# Load CSV file to Pandas DataFrame\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Rename columns to fit the desired schema\n",
    "df = df.rename(columns = {\n",
    "    'name': 'company_name',\n",
    "    'paid_at': 'updated_at'\n",
    "})\n",
    "\n",
    "convert_dict = {\n",
    "                'amount': float\n",
    "               } \n",
    "\n",
    "df = df.astype(convert_dict)\n",
    "\n",
    "# Filter rows by values.\n",
    "# In this case, extremely big numbers are eliminated from the table (This is because \n",
    "# we are not using these rows in the final view). Normally, this should\n",
    "# be fixed and verified in order to get the real numbers and company IDs\n",
    "df = df.query('amount < 1e6')\n",
    "df = df.query('company_id.astype(\"str\").str.len() == \"40\"')\n",
    "\n",
    "\n",
    "#Generate SQL schema with desired Data Types\n",
    "datatypes_sql = {\n",
    "    'id': types.VARCHAR(40),\n",
    "    'company_name': types.VARCHAR(130),\n",
    "    'company_id': types.VARCHAR(24),\n",
    "    'amount': types.DECIMAL(16,2),\n",
    "    'status': types.VARCHAR(30),\n",
    "    'created_at': types.TIMESTAMP,\n",
    "    'updated_at': types.TIMESTAMP\n",
    "}\n",
    "\n",
    "#Load data to AWS RDS MySQL instance\n",
    "df.to_sql('Operations',con=db,index=False,if_exists='replace', dtype=datatypes_sql) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "Separate the original table into Operations and Companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a connection to the DB\n",
    "connection = db.connect()\n",
    "\n",
    "#Create Queries to split tables into Companies and Transactions\n",
    "create_transactions = 'CREATE TABLE Transactions AS (SELECT id, company_id, amount, status, created_at, updated_at FROM Operations)'\n",
    "create_companies = 'CREATE TABLE Companies AS (SELECT DISTINCT company_id, company_name from Operations GROUP BY company_id)'\n",
    "\n",
    "connection.execute(create_transactions)\n",
    "connection.execute(create_companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "Create view where the user can see the sales per day per company and save it in RDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sales_view = 'select b.company_name, a.created_at, sum(a.amount) from Transactions a Left JOIN Companies b on a.company_id = b.company_id group by b.company_name, a.created_at'\n",
    "connection.execute(create_sales_view)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
